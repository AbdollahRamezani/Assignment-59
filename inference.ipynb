{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydub"
      ],
      "metadata": {
        "id": "aB-mt7IxuBk7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nrltcC7SUNZ6"
      },
      "outputs": [],
      "source": [
        "import pydub\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Saved_Models/audio_classification.h5')"
      ],
      "metadata": {
        "id": "tTEvYfkXuwFT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4-IlPq8IUABp"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/Dataset/Audio/dataset/Parisa/voice0.wav\"\n",
        "audio = pydub.AudioSegment.from_file(file_path)\n",
        "audio = audio.set_sample_width(2)\n",
        "audio = audio.set_frame_rate(48000)\n",
        "audio = audio.set_channels(1)\n",
        "chunks = pydub.silence.split_on_silence(audio, min_silence_len=2000, silence_thresh=-45)\n",
        "result = sum(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oTh_jx9R_HQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5342dcb9-ed93-417d-a5fb-d7403087c6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "someone send a voice:  Omid\n"
          ]
        }
      ],
      "source": [
        "persons = []\n",
        "for f in os.listdir(\"/content/drive/MyDrive/Dataset/Audio/dataset\"):\n",
        "    persons.append(f.split('.')[0])\n",
        "\n",
        "result.export(f\"new_file.wav\", format=\"wav\")\n",
        "path = \"new_file.wav\"\n",
        "x = tf.io.read_file(path)\n",
        "x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=48000,)\n",
        "x = tf.squeeze(x, axis=-1)\n",
        "x = x[tf.newaxis,...]\n",
        "\n",
        "pred = model(x)\n",
        "print(np.argmax(pred))\n",
        "print(\"someone send a voice: \",persons[np.argmax(pred)])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}